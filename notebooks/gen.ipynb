{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import json\n",
    "import argparse\n",
    "import treepoem\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from data_generator import gens, dims\n",
    "from augmentations import augs\n",
    "\n",
    "\n",
    "def load_json(fname, *args, **kwargs):\n",
    "    with open(fname) as f:\n",
    "        return json.load(f, *args, **kwargs)\n",
    "\n",
    "\n",
    "def save_json(jd, fname, *args, indent=4, **kwargs):\n",
    "    with open(fname, 'w') as f:\n",
    "        json.dump(jd, f, *args, indent=indent, **kwargs)\n",
    "\n",
    "\n",
    "def aligned_affine(bar, M, fix_position=True):\n",
    "    xps = [0, 0, 1, 1]\n",
    "    yps = [1, 0, 0, 1]\n",
    "    \n",
    "    height, width, _ = bar.shape\n",
    "    corners = np.array([[x*width, y*height, 1] for x, y in zip(xps, yps)]).T\n",
    "    \n",
    "    if fix_position:\n",
    "        M = M.copy()\n",
    "        M[:,-1] *= 0\n",
    "        M[:,-1] = -np.min(M@corners, axis=-1)\n",
    "\n",
    "    new_sz = np.ceil(np.max(M@corners, axis=-1)).astype(np.int32)\n",
    "    img = cv2.warpAffine(bar, M, new_sz)\n",
    "    return img, M@corners\n",
    "\n",
    "\n",
    "def generate_perspective_distort(img, alpha=0.1, beta=0.01):\n",
    "    xps = [0, 0, 1, 1]\n",
    "    yps = [1, 0, 0, 1]\n",
    "    height, width, _ = img.shape\n",
    "    corners = np.array([[x*width, y*height, 1] for x, y in zip(xps, yps)]).T\n",
    "\n",
    "    M = np.zeros((3,3))\n",
    "    M[:-1,:-1] = np.random.randn(2, 2)*alpha + np.eye(2)*(1.-alpha)\n",
    "    M[-1, :-1] = beta*np.abs(np.random.randn(1,2))\n",
    "    M[:-1,-1] *= 0\n",
    "    M[-1,-1] = 1\n",
    "    coords = (M@corners)[:-1]\n",
    "    M[:-1,-1] = -np.min(coords, axis=-1)\n",
    "    return M\n",
    "\n",
    "\n",
    "def generate_aligned_perspective_distort(img, scale=0.1):\n",
    "    xps = [0, 0, 1, 1]\n",
    "    yps = [1, 0, 0, 1]\n",
    "    height, width, _ = img.shape\n",
    "    corners = np.array([[x*width, y*height] for x, y in zip(xps, yps)])\n",
    "    corners_old = corners.copy()\n",
    "\n",
    "    dx, dy = np.random.exponential(scale=width*scale, size=corners.shape).T\n",
    "\n",
    "    corners[0,0] -= dx[0]\n",
    "    corners[0,1] += dy[0]\n",
    "\n",
    "    corners[1,0] -= dx[1]\n",
    "    corners[1,1] -= dy[1]\n",
    "\n",
    "    corners[2,0] += dx[2]\n",
    "    corners[2,1] -= dy[2]\n",
    "\n",
    "    corners[3,0] += dx[3]\n",
    "    corners[3,1] += dy[3]\n",
    "\n",
    "    theta = np.math.pi*np.random.random()*2\n",
    "    c, s = np.cos(theta), np.sin(theta)\n",
    "    R = np.array(((c, -s), (s, c)))\n",
    "\n",
    "    corners = corners@R\n",
    "\n",
    "    M = cv2.getPerspectiveTransform(corners_old.astype(np.float32), corners.astype(np.float32))\n",
    "\n",
    "    corners = np.array([[x*width, y*height, 1] for x, y in zip(xps, yps)]).T\n",
    "    M[:-1,-1] *= 0\n",
    "    M[-1,-1] = 1\n",
    "    coords = (M@corners)[:-1]\n",
    "    M[:-1,-1] = -np.min(coords, axis=-1)\n",
    "    coords = M@corners\n",
    "    coords = coords[:-1]/coords[-1]\n",
    "\n",
    "    new_sz = np.ceil(np.max(coords, axis=-1)).astype(np.int32)\n",
    "\n",
    "    return M\n",
    "\n",
    "\n",
    "def aligned_perspective(img, M):\n",
    "    xps = [0, 0, 1, 1]\n",
    "    yps = [1, 0, 0, 1]\n",
    "    height, width, _ = img.shape\n",
    "    corners = np.array([[x*width, y*height, 1] for x, y in zip(xps, yps)]).T\n",
    "    coords = M@corners\n",
    "    coords = coords[:-1]/coords[-1]\n",
    "    \n",
    "    new_sz = np.ceil(np.max(coords, axis=-1)).astype(np.int32)\n",
    "    \n",
    "    img = cv2.warpPerspective(img, M, new_sz)\n",
    "    return img, coords\n",
    "\n",
    "\n",
    "def coords_to_regions(coords, dimensions):\n",
    "    res = []\n",
    "    for i in range(len(coords)):\n",
    "        ptsx, ptsy = coords[i]\n",
    "        \n",
    "        res.append({\\\n",
    "        'shape_attributes': {\n",
    "            'name': 'polygon',\n",
    "            'all_points_x': list(ptsx),\n",
    "            'all_points_y': list(ptsy)\n",
    "        },\n",
    "        'region_attributes': {'barcode': dimensions[i]}})\n",
    "    return res\n",
    "\n",
    "\n",
    "def export(img, name, coords, dimensions):\n",
    "    #np.clip(img, 0, 1)\n",
    "    plt.imsave(f'{name}.jpg', img)\n",
    "    res = {f'{name}.jpg813086': {'filename': f'../code/{name}.jpg',\n",
    "    'size': 813086,\n",
    "    'regions': coords_to_regions(coords, dimensions),\n",
    "    'file_attributes': {}}}\n",
    "    save_json(res, f'{name}.json')\n",
    "\n",
    "\n",
    "def generate_distorted(barcode_types, content_barcodes, source_img=None, augms=[], distortions=None):\n",
    "    # barimgs = [treepoem.generate_barcode(typ, content) for typ, content in zip(barcode_types, content_barcodes)]\n",
    "    barimgs = [np.array(treepoem.generate_barcode(typ, content)) for typ, content in zip(barcode_types, content_barcodes)]\n",
    "    for aug_name in augms:\n",
    "        barimgs = [augs[aug_name](img) for img in barimgs]\n",
    "    if distortions is None:\n",
    "        distortions = [generate_aligned_perspective_distort(np.array(img)) for img in barimgs]\n",
    "    # imgs, coords = zip(*[aligned_affine(np.array(img), dis) for img, dis in zip(barimgs, distortions)])\n",
    "    imgs, coords = zip(*[aligned_perspective(np.array(img), dis) for img, dis in zip(barimgs, distortions)])\n",
    "    # masks, _ = zip(*[aligned_affine(np.ones_like(img), dis) for img, dis in zip(barimgs, distortions)])\n",
    "    masks, _ = zip(*[aligned_perspective(np.ones_like(img), dis) for img, dis in zip(barimgs, distortions)])\n",
    "    \n",
    "    if source_img is None:\n",
    "        width, height, _ = np.max([img.shape for img in imgs], axis=0)*len(imgs)//3\n",
    "        combined = np.zeros((width, height, 3), dtype=imgs[0].dtype)\n",
    "    else:\n",
    "        combined = plt.imread(source_img)[:,:,:3] if not isinstance(source_img, np.ndarray) else source_img\n",
    "        width, height, _ = combined.shape\n",
    "\n",
    "    for i in range(len(imgs)):\n",
    "        w, h, _ = imgs[i].shape\n",
    "        if width - w < 0 or height -h < 0:\n",
    "            continue\n",
    "        dw = np.random.randint(0, width - w)\n",
    "        dh = np.random.randint(0, height - h)\n",
    "        coords[i][0] += dh\n",
    "        coords[i][1] += dw\n",
    "        expanded_img = np.zeros_like(combined)\n",
    "        expanded_img[dw:w+dw, dh:h+dh] = imgs[i]\n",
    "        expanded_mask = np.zeros_like(combined)\n",
    "        expanded_mask[dw:w+dw, dh:h+dh] = masks[i]\n",
    "        combined = combined*(1-expanded_mask) + expanded_img\n",
    "    return combined, coords\n",
    "\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     parser = argparse.ArgumentParser(prog='Distorted barcode generator', description='''TODO''')\n",
    "#     parser.add_argument('-c', '--config', help='json config to generate image with barcodes', type=str)\n",
    "#     # parser.add_argument('-b', '--barcode_type', help='barcode type', type=str)\n",
    "#     # parser.add_argument('-c', '--content_barcode', help='barcode content', type=str)\n",
    "#     # parser.add_argument('-f', '--filename', help='name of the json markup and result img', type=str)\n",
    "#     # parser.add_argument('-d', '--dimension', help='1d or 2d barcode', type=str)\n",
    "#     parser.print_help()\n",
    "#     args = parser.parse_args()\n",
    "\n",
    "#     conf = load_json(args.config)\n",
    "#     contents = conf.get('barcode_contents', None)\n",
    "#     if contents is None:\n",
    "#         contents = [gens[bar_type]() for bar_type in conf['barcode_types']]\n",
    "#     img, coords = generate_distorted(conf['barcode_types'], contents, conf['source_img'],\n",
    "#                                      augms=conf.get('augmentations', []))\n",
    "#     dimensions = [dims[bar_type] for bar_type in conf['barcode_types']]\n",
    "#     export(img, conf['name'], coords, dimensions)\n",
    "\n",
    "#     # barimg = treepoem.generate_barcode(args.barcode_type, args.content_barcode)\n",
    "#     # img, coords = aligned_affine(np.array(barimg), np.random.randn(2, 3))\n",
    "#     # export(img, coords, args.filename, args.dimension)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "barcode_types = [\"ean13\", \"qrcode\"]\n",
    "barcode_contents = [\"100000011111\", \"1\", \"110\", \"1\", \"1\", \"1\", \"1\"]\n",
    "barcode_dimensions = [\"1d\", \"1d\", \"1d\", \"1d\", \"1d\", \"1d\", \"1d\"]\n",
    "# source_img = \"./example.jpg\"\n",
    "source_img = (np.random.rand(128, 128, 3) * 255).astype(np.uint8)\n",
    "augmentations = [\"Folding\", \"BadPhotoCopy\", \"LightingGradient\"]\n",
    "img, coords= generate_distorted(\n",
    "    barcode_types=barcode_types,\n",
    "    content_barcodes=barcode_contents,\n",
    "    source_img=source_img,\n",
    "    augms=augmentations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[  0.        , 162.48724866, 182.67316024,  25.44391159],\n",
       "        [ 44.39089658,   0.        , 254.46881421, 337.22624345]]),\n",
       " array([[ 91.03433199,   0.        ,  42.4588058 , 128.54048876],\n",
       "        [134.69949979,  87.23170488,   0.        ,  41.23573165]]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 128, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.from_numpy(img.transpose(2, 0, 1))[None].to(torch.float32) / 255\n",
    "xx = F.interpolate(x, scale_factor=2, mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hubenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
